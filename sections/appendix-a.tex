\section{Appendix}
\subsection{Mathematical Proofs and Derivations}

This appendix contains detailed mathematical proofs and derivations supporting key results presented in the thesis. We include justifications for fundamental limits, optimization dynamics of GANs, and analysis of minimax formulations.

\subsection{Limit Justification}
\label{sec:limit-justification}
We prove the limit $\lim_{x \to 0} x\log{x} = 0$ using L'HÃ´pital's rule, which is fundamental for analyzing entropy calculations in information theory.

\begin{align}
	\label{justification:lhospital}
	\lim_{x \to 0} x\log{x} & = \lim_{x \to 0} {\log{x} \frac {1 \frac x}}        \\
	                        & = \lim_{x \to 0} {{1 \frac x} \frac {-1 \frac x^2}} \\
	                        & = \lim_{x \to 0} {-x^2 \frac x}                     \\
	                        & = \lim_{x \to 0} -x                                 \\
	                        & = 0
\end{align}

\subsection{Optimization Dynamics}
\label{sec:proof-for-jsd-thing}
We derive the relationship between the Jensen-Shannon divergence (JSD) and the GAN objective function. This shows that minimizing the GAN loss is equivalent to minimizing the JSD between the real and generated data distributions.

\begin{small}
	\begin{align}
		 & \mathbb{E}\left[\log{{\ptx \frac \pgx + \ptx}}\right] + \mathbb{E}\left[\log{\pgx\frac\pgx + \ptx}\right] + \log4 - \log4 \nonumber \\
		 & = \sum_{x}\ptx\log{\ptx \frac \pgx + \ptx} + \sum_{x}\pgx\log{\pgx \frac \pgx + \ptx} + \log4 - \log4 \nonumber                     \\
		 & = \sum_{x}\ptx\log{\ptx \frac \pgx + \ptx} + \sum_{x}\pgx\log{\pgx \frac \pgx + \ptx} + \log2 + \log2 - \log4 \nonumber             \\
		 & = \sum_{x}\ptx\log{\ptx \frac \pgx + \ptx} + \sum_{x}\pgx\log{\pgx
		\frac \pgx + \ptx} \nonumber                                                                                                           \\
		 & \quad + \sum_{x}\ptx\log2 + \sum_{x}\pgx\log2 - \log4 \nonumber                                                                     \\
		 & = \sum_{x}\ptx\log{2\ptx \frac \pgx + \ptx} + \sum_{x}\pgx\log{2\pgx \frac \pgx + \ptx} - \log4 \nonumber                           \\
		 & = \sum_{x}\ptx\log{\ptx \frac {\pgx + \ptx \frac 2}} + \sum_{x}\pgx\log{\pgx \frac {\pgx + \ptx \frac 2}} - \log4 \nonumber         \\
		 & = \KL{\ptx}{\pgx + \ptx \frac 2} + \KL{\pgx}{\pgx+\ptx \frac 2} - \log4 \nonumber                                                   \\
		 & = 2 \cdot \JSD{\pgx}{\ptx} - \log4 \label{eq:jsd-derivation}
	\end{align}
\end{small}

Equation \ref{eq:jsd-derivation} establishes the connection between the GAN objective and JSD, demonstrating that the optimal discriminator corresponds to the JSD between the real and generated distributions.

\subsection{Minimax Analysis of GAN Objectives}
\label{sec:minimax-analysis}
We analyze the minimax and maximin values of the discriminator ($\VD$) and generator ($\VG$) objectives, providing theoretical foundations for understanding GAN convergence properties.

\subsubsection{Minimax of $\VD$}
\label{sec:minimax-vd}
\begin{align}
	\fracline{\VD} & = \min_{\mathbf{\phi}}\max_{\mathbf{\theta}}
	V_{\D}(\theta, \phi) \nonumber                                              \\
	               & = \min_{\mathbf{\phi}}\max_{\mathbf{\theta}} \left (
	\mathbb{E}\left[\log{\D(x)}\right] +
	\mathbb{E}\left[\log(1 -
	\D(\G(\mathbf{z})))\right] \right) \nonumber                                \\
	               & = \min_{\mathbf{\phi}}\left(\max_{\mathbf{\theta}} \left (
		\mathbb{E}\left[\log{\D(x)}\right] +
		\mathbb{E}\left[\log(1 -
				\D(\G(\mathbf{z})))\right] \right)
	\right) \nonumber                                                           \\
	               & = \min_{\phi}\left(\mathbb{E}\left[\log{\pt \frac
			\pg + \pt}\right] + \mathbb{E}\left[\log\left(1 - {\pt \frac
	\pg + \pt}\right)\right] \right) \nonumber                                  \\
	               & = \mathbb{E}\left[\log{\pt \frac \pt + \pt}\right] +
	\mathbb{E}\left[\log\left(1 - {\pt \frac
	\pt + \pt}\right)\right] \nonumber                                          \\
	               & = \mathbb{E}\left[\log{1 \frac 2}\right] +
	\mathbb{E}\left[\log{\left(1 - {1 \frac 2}\right)}\right] \nonumber         \\
	               & = \log{1 \frac 2} + \log{1 \frac 2} \nonumber              \\
	               & = \log{1 \frac 4} \label{eq:minimax-vd}
\end{align}

Equation \ref{eq:minimax-vd} shows that the minimax value of the discriminator objective is $\log(1/4)$, achieved when the generator perfectly matches the real data distribution.

\subsubsection{Maximin of $\VD$}
\label{sec:maximin-vd}
\begin{align}
	\underline{\VD} & =
	\max_{\mathbf{\theta}}\min_{\mathbf{\phi}}V_{\D}(\theta,
	\phi) \nonumber                                                                                                                  \\
	                & =
	\max_{\mathbf{\theta}}\min_{\mathbf{\phi}} \left(
	\mathbb{E}\left[\log{\D(x)}\right] +
	\mathbb{E}\left[\log(1 - \D(\G(\mathbf{z})))\right]\right) \nonumber                                                             \\
	                & = \max_{\mathbf{\theta}}\left(\min_{\mathbf{\phi}} \left(
		\mathbb{E}\left[\log{\D(x)}\right] +
		\mathbb{E}\left[\log(1 -
	\D(\G(\mathbf{z})))\right]\right)\right) \nonumber                                                                               \\
	                & = \max_{\mathbf{\theta}}\left(\left(
		\mathbb{E}\left[\log{\D(x)}\right] +
		\mathbb{E}\left[\log(1 -
	\D(x))\right]\right)\right) \nonumber                                                                                            \\
	                & = \max_{\mathbf{\theta}}\left(\left(
		\mathbb{E}\left[\log{\D(x)} +
	\log(1 - \D(x))\right]\right)\right) \nonumber                                                                                   \\
	                & = \mathbb{E}\left[\log{\pt \frac \pt + \pt}\right]
	+ \mathbb{E}\left[\log\left(1 - {\pt \frac \pt + \pt}\right)\right] \nonumber                                                    \\
	                & = \mathbb{E}\left[\log{1 \frac 2}\right] + \mathbb{E}\left[\log{\left(1 - {1 \frac 2}\right)}\right] \nonumber \\
	                & = \log{1 \frac 2} + \log{1 \frac 2} \nonumber                                                                  \\
	                & = \log{1 \frac 4} \label{eq:maximin-vd}
\end{align}

Equation \ref{eq:maximin-vd} demonstrates that the maximin value of the discriminator objective also equals $\log(1/4)$, confirming the existence of a saddle point in the GAN game.

\subsubsection{Minimax of $\VG$}
\label{sec:minimax-vg}
\begin{align}
	\fracline{\VG} & = \min_{\theta}\max_{\phi} \VG \nonumber        \\
	               & = \min_{\theta}\max_{\mathbf{\phi}}
	\left (-\mathbb{E}\left[\log{\D(x)}\right] -
	\mathbb{E}\left[\log(1 -
	\D(\G(\mathbf{z})))\right] \right) \nonumber                     \\
	               & = \min_{\theta}\left(\max_{\mathbf{\phi}}
	\left (-\mathbb{E}\left[\log{\D(x)}\right] -
		\mathbb{E}\left[\log(1 -
				\D(\G(\mathbf{z})))\right] \right)
	\right) \nonumber                                                \\
	               & = \min_{\theta}\left(
	-\mathbb{E}\left[\log{\D(x)}\right] -
	\mathbb{E}\left[\log(1 -
	\D(x))\right] \right) \nonumber                                  \\
	               & = \min_{\theta}\left(
	-\mathbb{E}\left[\log{\D(x)} +
	\log(1 - \D(x))\right] \right) \nonumber                         \\
	               & = -\mathbb{E}\left[\log{\pt \frac \pt + \pt} +
	\log\left(1 - {\pt \frac \pt + \pt}\right)\right] \nonumber      \\
	               & = - \mathbb{E}\left[\log{1 \frac 2} +
	\log{\left(1 - {1 \frac 2}\right)}\right] \nonumber              \\
	               & = - \log{1 \frac 2} - \log{1 \frac 2} \nonumber \\
	               & = - \log{1 \frac 4} \label{eq:minimax-vg}
\end{align}

Equation \ref{eq:minimax-vg} shows that the minimax value of the generator objective is $-\log(1/4)$, which is the negative of the discriminator's minimax value.

\subsubsection{Maximin of $\VG$}
\label{sec:maximin-vg}
\begin{align}
	\underline{\VG} & = \max_{\mathbf{\phi}} \min_{\mathbf{\theta}}\VG \nonumber \\
	                & = \max_{\mathbf{\phi}}\min_{\mathbf{\theta}}\VG \nonumber  \\
	                & = \max_{\phi}\min_{\theta} \left(
	-\mathbb{E}\left[\log{\D(x)}\right] -
	\mathbb{E}\left[\log(1 -
	\D(\G(\mathbf{z})))\right] \right) \nonumber                                 \\
	                & = \max_{\phi}\left(\min_{\theta} \left(
		-\mathbb{E}\left[\log{\D(x)}\right] -
		\mathbb{E}\left[\log(1 -
				\D(\G(\mathbf{z})))\right] \right)
	\right) \nonumber                                                            \\
	                & = \max_{\phi}\left(
	-\mathbb{E}\left[\log{\pt \frac \pt + \pg} +
	\log(1 -
	{\pt \frac \pt + \pg}\right] \right) \nonumber                               \\
	                & =
	-\mathbb{E}\left[\log{\pt \frac \pt + \pt} +
		\log(1 -
	{\pt \frac \pt + \pt})\right] \nonumber                                      \\
	                & = - \mathbb{E}\left[\log{1 \frac 2} +
	\log{\left(1 - {1 \frac 2}\right)}\right] \nonumber                          \\
	                & = - \log{1 \frac 2} - \log{1 \frac 2} \nonumber            \\
	                & = - \log{1 \frac 4} \label{eq:maximin-vg}
\end{align}

Equation \ref{eq:maximin-vg} confirms that the maximin value of the generator objective equals $-\log(1/4)$, consistent with the minimax value and demonstrating the stability of the GAN optimization problem.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End:
